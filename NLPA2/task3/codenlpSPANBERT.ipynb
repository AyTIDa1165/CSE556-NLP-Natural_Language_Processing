{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "execution_failed": "2025-03-19T05:32:23.644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:24:19.447283Z",
     "iopub.status.busy": "2025-03-19T16:24:19.446939Z",
     "iopub.status.idle": "2025-03-19T16:24:19.452356Z",
     "shell.execute_reply": "2025-03-19T16:24:19.451263Z",
     "shell.execute_reply.started": "2025-03-19T16:24:19.447252Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    }
   ],
   "source": [
    "print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:24:23.949811Z",
     "iopub.status.busy": "2025-03-19T16:24:23.949526Z",
     "iopub.status.idle": "2025-03-19T16:24:27.250216Z",
     "shell.execute_reply": "2025-03-19T16:24:27.249179Z",
     "shell.execute_reply.started": "2025-03-19T16:24:23.949790Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-crf in /usr/local/lib/python3.10/dist-packages (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-crf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:24:31.189801Z",
     "iopub.status.busy": "2025-03-19T16:24:31.189477Z",
     "iopub.status.idle": "2025-03-19T16:24:31.223702Z",
     "shell.execute_reply": "2025-03-19T16:24:31.222936Z",
     "shell.execute_reply.started": "2025-03-19T16:24:31.189777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CELL_1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import (AutoTokenizer, AutoModelForQuestionAnswering,\n",
    "                          AutoModel, AdamW, get_linear_schedule_with_warmup, AutoConfig)\n",
    "from datasets import load_dataset\n",
    "from torchcrf import CRF\n",
    "print(\"CELL_1\")\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(message)s\", level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "def exact_match_score(predictions, references):\n",
    "    assert len(predictions) == len(references), \"Lists must have the same length\"\n",
    "    matches = sum(p == r for p, r in zip(predictions, references))\n",
    "    return matches / len(references) * 100 \n",
    "\n",
    "def preprocess_standard(example, tokenizer, max_length=384, doc_stride=128):\n",
    "    \"\"\"\n",
    "    Tokenizes the question and context, then computes start/end token indices for the answer.\n",
    "    For unanswerable questions, positions are set to 0.\n",
    "    \"\"\"\n",
    "    question = example['question']\n",
    "    context = example['context']\n",
    "    if len(example['answers']['answer_start']) == 0:\n",
    "        answer_text = \"\"\n",
    "        start_char = 0\n",
    "    else:\n",
    "        answer_text = example['answers']['text'][0]\n",
    "        start_char = example['answers']['answer_start'][0]\n",
    "    tokenized = tokenizer.encode_plus(\n",
    "        question,\n",
    "        context,\n",
    "        truncation=\"only_second\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "    tokenized = {key: val[0] if isinstance(val, list) else val for key, val in tokenized.items()}\n",
    "    offsets = tokenized.pop(\"offset_mapping\")\n",
    "    if answer_text == \"\":\n",
    "        tokenized['start_positions'] = 0\n",
    "        tokenized['end_positions'] = 0\n",
    "    else:\n",
    "        end_char = start_char + len(answer_text)\n",
    "        start_token, end_token = 0, 0\n",
    "        for i, (start, end) in enumerate(offsets):\n",
    "            if start <= start_char < end:\n",
    "                start_token = i\n",
    "            if start < end_char <= end:\n",
    "                end_token = i\n",
    "                break\n",
    "        tokenized['start_positions'] = start_token\n",
    "        tokenized['end_positions'] = end_token\n",
    "    return tokenized\n",
    "\n",
    "def preprocess_crf(example, tokenizer, max_length=384, doc_stride=128):\n",
    "    question = example['question']\n",
    "    context = example['context']\n",
    "    if len(example['answers']['answer_start']) == 0:\n",
    "        answer_text = \"\"\n",
    "        start_char = None\n",
    "        end_char = None\n",
    "    else:\n",
    "        answer_text = example['answers']['text'][0]\n",
    "        start_char = example['answers']['answer_start'][0]\n",
    "        end_char = start_char + len(answer_text)\n",
    "    tokenized = tokenizer.encode_plus(\n",
    "        question,\n",
    "        context,\n",
    "        truncation=\"only_second\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=False,\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "    offsets = tokenized.pop(\"offset_mapping\")\n",
    "    labels = [0] * len(offsets)\n",
    "    if answer_text != \"\":\n",
    "        started = False\n",
    "        for i, (start, end) in enumerate(offsets):\n",
    "            if start == 0 and end == 0:\n",
    "                continue\n",
    "            if start >= start_char and end <= end_char:\n",
    "                if not started:\n",
    "                    labels[i] = 1  # B\n",
    "                    started = True\n",
    "                else:\n",
    "                    labels[i] = 2  # I\n",
    "    tokenized['labels'] = labels\n",
    "    return tokenized\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, preprocess_fn):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.dataset[idx]\n",
    "        processed = self.preprocess_fn(example, self.tokenizer)\n",
    "        return processed\n",
    "\n",
    "def collate_fn(batch, tokenizer):\n",
    "    batch = tokenizer.pad(batch, return_tensors=\"pt\")\n",
    "    return batch\n",
    "\n",
    "class SpanBERTCRFForQA(nn.Module):\n",
    "    def __init__(self, model_name, num_labels=3):\n",
    "        super(SpanBERTCRFForQA, self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.spanbert = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.config.hidden_size, num_labels)\n",
    "        self.crf = CRF(num_labels, batch_first=True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.spanbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        emissions = self.classifier(sequence_output)  # (batch, seq_len, num_labels) ! ! ! ! \n",
    "        if labels is not None:\n",
    "            loss = -self.crf(emissions, labels, mask=attention_mask.bool(), reduction='mean')\n",
    "            return loss\n",
    "        else:\n",
    "            prediction = self.crf.decode(emissions, mask=attention_mask.bool())\n",
    "            return prediction\n",
    "\n",
    "def bio_tags_to_answer(pred_tags, input_ids, tokenizer, example):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    answer_tokens = []\n",
    "    found = False\n",
    "    for tag, token in zip(pred_tags, tokens):\n",
    "        if tag == 1:\n",
    "            found = True\n",
    "            answer_tokens.append(token)\n",
    "        elif found and tag == 2:\n",
    "            answer_tokens.append(token)\n",
    "        elif found:\n",
    "            break\n",
    "    if answer_tokens:\n",
    "        answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "        return answer.strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def train_standard(model, train_loader, val_loader, optimizer, scheduler, device, epochs=6):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                            start_positions=start_positions, end_positions=end_positions)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        logger.info(f\"[Standard QA] Epoch {epoch+1}/{epochs} - Training Loss: {avg_train_loss:.4f}\")\n",
    "        \n",
    "        # Validation!!!\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                start_positions = batch['start_positions'].to(device)\n",
    "                end_positions = batch['end_positions'].to(device)\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                                start_positions=start_positions, end_positions=end_positions)\n",
    "                loss = outputs.loss\n",
    "                total_val_loss += loss.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        logger.info(f\"[Standard QA] Epoch {epoch+1}/{epochs} - Validation Loss: {avg_val_loss:.4f}\")\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def train_crf(model, train_loader, val_loader, optimizer, scheduler, device, epochs=6):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        logger.info(f\"[CRF QA] Epoch {epoch+1}/{epochs} - Training Loss: {avg_train_loss:.4f}\")\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                total_val_loss += loss.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        logger.info(f\"[CRF QA] Epoch {epoch+1}/{epochs} - Validation Loss: {avg_val_loss:.4f}\")\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def evaluate_standard(model, loader, tokenizer, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            start_logits = outputs.start_logits\n",
    "            end_logits = outputs.end_logits\n",
    "            for i in range(input_ids.size(0)):\n",
    "                start_index = torch.argmax(start_logits[i]).item()\n",
    "                end_index = torch.argmax(end_logits[i]).item()\n",
    "                pred_ids = input_ids[i][start_index:end_index+1]\n",
    "                pred_answer = tokenizer.decode(pred_ids, skip_special_tokens=True)\n",
    "                predictions.append(pred_answer.strip())\n",
    "            for i in range(input_ids.size(0)):\n",
    "                start_pos = batch['start_positions'][i].item()\n",
    "                end_pos = batch['end_positions'][i].item()\n",
    "                ref_ids = input_ids[i][start_pos:end_pos+1]\n",
    "                ref_answer = tokenizer.decode(ref_ids, skip_special_tokens=True)\n",
    "                references.append(ref_answer.strip())\n",
    "    score = exact_match_score(predictions, references)\n",
    "    logger.info(f\"[Standard QA] Exact Match Score: {score:.2f}%\")\n",
    "    return score\n",
    "\n",
    "def evaluate_crf(model, loader, tokenizer, device, original_dataset):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            batch_preds = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            for i in range(len(batch_preds)):\n",
    "                pred_tags = batch_preds[i]\n",
    "                example = original_dataset[idx]\n",
    "                answer = bio_tags_to_answer(pred_tags, input_ids[i].cpu().tolist(), tokenizer, example)\n",
    "                predictions.append(answer)\n",
    "                if len(example['answers']['text']) > 0:\n",
    "                    references.append(example['answers']['text'][0].strip())\n",
    "                else:\n",
    "                    references.append(\"\")\n",
    "                idx += 1\n",
    "    score = exact_match_score(predictions, references)\n",
    "    logger.info(f\"[CRF QA] Exact Match Score: {score:.2f}%\")\n",
    "    return score\n",
    "\n",
    "def plot_losses(train_losses, val_losses, title, filename):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:27:02.866728Z",
     "iopub.status.busy": "2025-03-19T16:27:02.866350Z",
     "iopub.status.idle": "2025-03-19T18:01:30.615726Z",
     "shell.execute_reply": "2025-03-19T18:01:30.614890Z",
     "shell.execute_reply.started": "2025-03-19T16:27:02.866705Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CELL_2\n",
      "Using device: cuda\n",
      "Loading SQuAD v2 dataset...\n",
      "Dataset loaded. Training samples: 15000 Validation samples: 1000\n",
      "Setting up Standard QA datasets and dataloaders...\n",
      "Initializing Standard QA model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at SpanBERT/spanbert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for Standard SpanBERT QA model...\n",
      "Standard QA - Epoch 1 training started.\n",
      "Standard QA - Epoch 1 completed. Training Loss: 2.3790, Validation Loss: 1.9067, EM Score: 39.30%\n",
      "Standard QA - Epoch 2 training started.\n",
      "Standard QA - Epoch 2 completed. Training Loss: 1.5690, Validation Loss: 1.7594, EM Score: 46.10%\n",
      "Standard QA - Epoch 3 training started.\n",
      "Standard QA - Epoch 3 completed. Training Loss: 1.1832, Validation Loss: 1.8329, EM Score: 51.60%\n",
      "Standard QA - Epoch 4 training started.\n",
      "Standard QA - Epoch 4 completed. Training Loss: 0.9324, Validation Loss: 1.9935, EM Score: 53.20%\n",
      "Standard QA - Epoch 5 training started.\n",
      "Standard QA - Epoch 5 completed. Training Loss: 0.7720, Validation Loss: 2.2132, EM Score: 53.40%\n",
      "Standard QA - Epoch 6 training started.\n",
      "Standard QA - Epoch 6 completed. Training Loss: 0.6873, Validation Loss: 2.2892, EM Score: 54.60%\n",
      "Standard QA training completed.\n",
      "Standard QA model saved in models/standard_spanbert_qa.\n",
      "Standard QA training plot saved as standard_loss.png.\n"
     ]
    }
   ],
   "source": [
    "print(\"CELL_2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "print(f\"Using device: {device}\")\n",
    "model_name = \"SpanBERT/spanbert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(\"Loading SQuAD v2 dataset...\")\n",
    "squad = load_dataset(\"squad_v2\")\n",
    "train_subset = squad['train'].shuffle(seed=42).select(range(15000))\n",
    "val_subset = squad['validation'].shuffle(seed=42).select(range(1000))\n",
    "print(\"Dataset loaded. Training samples:\", len(train_subset), \"Validation samples:\", len(val_subset))\n",
    "\n",
    "print(\"Setting up Standard QA datasets and dataloaders...\")\n",
    "train_dataset_standard = QADataset(train_subset, tokenizer, preprocess_standard)\n",
    "val_dataset_standard = QADataset(val_subset, tokenizer, preprocess_standard)\n",
    "train_loader_standard = DataLoader(train_dataset_standard, batch_size=8, shuffle=True,\n",
    "                                   collate_fn=lambda x: collate_fn(x, tokenizer))\n",
    "val_loader_standard = DataLoader(val_dataset_standard, batch_size=8, shuffle=False,\n",
    "                                 collate_fn=lambda x: collate_fn(x, tokenizer))\n",
    "\n",
    "print(\"Initializing Standard QA model...\")\n",
    "standard_model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "standard_model.to(device)\n",
    "\n",
    "# Use weight decay for regularization\n",
    "optimizer_std = AdamW(standard_model.parameters(), lr=3e-5, weight_decay=0.01)\n",
    "total_steps_std = len(train_loader_standard) * 6  # 6 epochs\n",
    "scheduler_std = get_linear_schedule_with_warmup(optimizer_std, num_warmup_steps=0, num_training_steps=total_steps_std)\n",
    "\n",
    "\n",
    "def train_standard(model, train_loader, val_loader, optimizer, scheduler, device, epochs=6):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Standard QA - Epoch {epoch+1} training started.\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                            start_positions=start_positions, end_positions=end_positions)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        logger.info(f\"[Standard QA] Epoch {epoch+1}/6 - Training Loss: {avg_train_loss:.4f}\")\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                start_positions = batch['start_positions'].to(device)\n",
    "                end_positions = batch['end_positions'].to(device)\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                                start_positions=start_positions, end_positions=end_positions)\n",
    "                loss = outputs.loss\n",
    "                total_val_loss += loss.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        logger.info(f\"[Standard QA] Epoch {epoch+1}/6 - Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        em_score = evaluate_standard(model, val_loader, tokenizer, device)\n",
    "        print(f\"Standard QA - Epoch {epoch+1} completed. Training Loss: {avg_train_loss:.4f}, \"\n",
    "              f\"Validation Loss: {avg_val_loss:.4f}, EM Score: {em_score:.2f}%\")\n",
    "    return train_losses, val_losses\n",
    "\n",
    "print(\"Starting training for Standard SpanBERT QA model...\")\n",
    "train_losses_std, val_losses_std = train_standard(standard_model, train_loader_standard, val_loader_standard,\n",
    "                                                  optimizer_std, scheduler_std, device, epochs=6)\n",
    "logger.info(\"Standard QA model training completed.\")\n",
    "print(\"Standard QA training completed.\")\n",
    "\n",
    "std_exact_match = evaluate_standard(standard_model, val_loader_standard, tokenizer, device)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "standard_model.save_pretrained(\"models/standard_spanbert_qa\")\n",
    "tokenizer.save_pretrained(\"models/standard_spanbert_qa\")\n",
    "logger.info(\"Standard QA model saved in models/standard_spanbert_qa.\")\n",
    "print(\"Standard QA model saved in models/standard_spanbert_qa.\")\n",
    "\n",
    "plot_losses(train_losses_std, val_losses_std, \"Standard SpanBERT QA Training\", \"standard_loss.png\")\n",
    "logger.info(\"Standard QA training plot saved as standard_loss.png.\")\n",
    "print(\"Standard QA training plot saved as standard_loss.png.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
